{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreparation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u_tMyZQczoR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import sklearn\n",
        "from sklearn.metrics import *\n",
        "from sklearn import preprocessing\n",
        "import itertools"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gstcd3otz2BQ"
      },
      "source": [
        "def extend_to_right_boundary(df, max_time):\n",
        "  df_tmp = df.reset_index(level = 0, drop = True).sort_index(ascending=True)\n",
        "  min_left = min(df.index)[1]\n",
        "  extended_time = pd.date_range(start = min_left, end = max_time, freq ='W-Mon')\n",
        "  df_tmp = df_tmp.reindex(extended_time, fill_value = 0.0)\n",
        "  df_tmp.index.name = \"DateTime\"\n",
        "  #print((df.index.get_level_values(level = 0).unique(), extended_time))\n",
        "\n",
        "  # this does not work\n",
        "  # weekly_sales.loc[[3129],:].reindex(index = multiindex.at[3129], level = \"DateTime\", fill_value = 0.0)\n",
        "\n",
        "  return df_tmp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqvux18z-Zq"
      },
      "source": [
        "def prepare_sales_data(sales_df, categories_df, traffic_df, extend_to_common_horizon = False, extend_only_to_max_date = False, shift_list = [None]):\n",
        "  sales_df_copy = sales_df.copy()\n",
        "  sales_df_copy['DateTime'] = sales_df_copy['week_starting_date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
        "  weekly_sales = sales_df_copy.groupby([\"product_id\", \"DateTime\"], as_index=True).agg({'sales':'sum'}) # czy to jest potrzebne?\n",
        "\n",
        "  if extend_to_common_horizon:\n",
        "    if extend_only_to_max_date:\n",
        "      max_time_value = max(weekly_sales.index.get_level_values(level = 1))\n",
        "      expanded_full = weekly_sales.groupby(level=0).apply(lambda x: extend_to_right_boundary(x, max_time_value))\n",
        "    else:\n",
        "      t1 = weekly_sales.index.get_level_values(level = 0).unique()\n",
        "      t2 = weekly_sales.index.get_level_values(level = 1).unique()\n",
        "      new_index = list(itertools.product(t1, t2))\n",
        "      expanded_full = weekly_sales.reindex(pd.MultiIndex.from_tuples(new_index, names=['product_id', 'DateTime']), fill_value=0)\n",
        "  else:\n",
        "    expanded_full = weekly_sales.groupby(level=0).apply(lambda x: x.reset_index(level=0, drop=True).asfreq(\"W-Mon\", fill_value = 0.0))\n",
        "    #expanded_full = weekly_sales.groupby(level=0).apply(lambda x: x.reset_index(level=0, drop=True).asfreq(\"W-Mon\").fillna(0))\n",
        "  \n",
        "  \n",
        "\n",
        "  full_sales_dataset = expanded_full\\\n",
        "  .merge(categories_df, left_index=True, right_index = True,  how = 'left')\\\n",
        "  .merge(traffic_df, left_index = True,  right_index = True, how = 'left')\n",
        "\n",
        "  full_sales_dataset[\"Date\"] = full_sales_dataset.index.get_level_values(level = 1)\n",
        "  \n",
        "  # adding columns based on start time\n",
        "  full_sales_dataset['Week_numb'] = full_sales_dataset['Date'].apply(lambda x: int(x.strftime(\"%V\")))\n",
        "  full_sales_dataset['YW'] = full_sales_dataset['Date'].apply(lambda x: int(x.strftime(\"%Y%V\")))\n",
        "  full_sales_dataset['Month'] = full_sales_dataset['Date'].apply(lambda x: int(x.month))\n",
        "\n",
        "  if shift_list[0] is not None:\n",
        "    for i in shift_list:\n",
        "      # do this but within groups, otherwise there is a bug\n",
        "      full_sales_dataset[[f\"sales_lag_{i}W\", f\"traffic_lag_{i}W\"]] = full_sales_dataset.groupby(level = 0)[['sales', 'traffic']].shift(i, fill_value = 0.0)\n",
        "\n",
        "  #full_sales_dataset[\"sales_to_traffic\"] = full_sales_dataset.sales/full_sales_dataset.traffic\n",
        "  \n",
        "  full_sales_dataset.drop(\"Date\", axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "  return full_sales_dataset\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l4wt29_c30x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}